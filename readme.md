### Loss Functions

For MSE (Mean Squared Error):
$$
Loss = \frac{1}{N} \sum_{i=1}^{N} (y_{i} - \hat{y}_{i})^2
$$

For Cross-Entropy:
$$
Loss = -\sum_{i=1}^{N} y_{i} \cdot \log(\hat{y}_{i})
$$
